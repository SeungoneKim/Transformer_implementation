import torch.optim as optim

def loss():
    NotImplementedError

def scheduler():
    NotImplementedError

optimizer = optim.Adam()